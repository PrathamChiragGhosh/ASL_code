{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a168ed9-13c3-4765-a0ec-12f0a85a2247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "\n",
    "# Load your pre-trained classifier model (adjust the path to your model)\n",
    "model = load_model('asl_resnet.h5',compile = False)\n",
    "\n",
    "# Class labels for ASL (A-Z, space, delete, etc.)\n",
    "\n",
    "# Set up camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "class_labels = {i: chr(65 + i) for i in range(26)}\n",
    "class_labels[26] = 'Delete'\n",
    "class_labels[27] = 'Space'\n",
    "class_labels[28] = 'Nothing'\n",
    "\n",
    "\n",
    "last_prediction_time = time.time()\n",
    "# Function to preprocess the image before sending it to the classifier\n",
    "def preprocess_image(image, size=(64, 64)):  # Adjust size as per your model's input\n",
    "    image = cv2.resize(image, size)\n",
    "    image = np.array(image, dtype='float32')\n",
    "    image = image / 255.0  # Normalize if your model requires it\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "# Function to draw a rectangle (demarcated area)\n",
    "def draw_demarcation(frame):\n",
    "    height, width, _ = frame.shape\n",
    "    x_start, y_start, x_end, y_end = int(width * 0.3), int(height * 0.2), int(width * 0.7), int(height * 0.8)\n",
    "    cv2.rectangle(frame, (x_start, y_start), (x_end, y_end), (0, 255, 0), 2)\n",
    "    return frame, (x_start, y_start, x_end, y_end)\n",
    "def check_condition(recognized_text, recognized_letter):\n",
    "    if recognized_letter ==\"Space\" :\n",
    "        recognized_text.append(\" \")\n",
    "    elif recognized_letter == \"Delete\":\n",
    "        recognized_text = recognized_text[:-7]\n",
    "\n",
    "    return recognized_text\n",
    "        \n",
    "# Main loop\n",
    "recognized_text = ''\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Flip the frame horizontally for a mirror effect\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Draw the demarcated area\n",
    "    frame, (x_start, y_start, x_end, y_end) = draw_demarcation(frame)\n",
    "\n",
    "    # Extract the region of interest (ROI) for classification\n",
    "    roi = frame[y_start:y_end, x_start:x_end]\n",
    "    # Preprocess the ROI\n",
    "    \n",
    "    if time.time() - last_prediction_time >= 2:\n",
    "        processed_roi = preprocess_image(roi)\n",
    "        # Use the classifier to predict the gesture\n",
    "        prediction = model.predict(processed_roi)\n",
    "        predicted_class = np.argmax(prediction)\n",
    "        recognized_letter = class_labels[predicted_class]\n",
    "    \n",
    "        # Add recognized letter to the text\n",
    "        recognized_text += recognized_letter\n",
    "        recognized_text = check_condition(recognized_text,recognized_letter)\n",
    "        last_prediction_time = time.time()\n",
    "\n",
    "    # Display the actual camera feed with the demarcated area\n",
    "    cv2.imshow('Camera Feed', frame)\n",
    "    \n",
    "    # Display the recognized text in a separate window\n",
    "    text_frame = np.zeros((300, 600, 3), dtype='uint8')  # Black background\n",
    "    cv2.putText(text_frame, f'Recognized Text: {recognized_text}', (30, 150),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    cv2.imshow('Recognized Text', text_frame)\n",
    "\n",
    "    # Exit when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a869b2-b0ee-4c47-9aee-23046c503448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5040be-3e5e-4c77-bfac-ccd564464787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
